% !TeX root = ..\dyplom-template.tex

\chapter{Перший розділ}\label{chapter1}

\section{Огляд моделей текстур}\label{section1.overview}

У загальному випадку ми працюємо із кольоровими цифровими зображеннями із трьома і більше 8-бітними каналами, 
проте наразі обмежимося одноканальними зображеннями.

Модель текстури грубо можна визначити як набір статистик таких, що два зображення мають однакову текстуру тоді і лише тоді, коли значення цих статистик близькі;
при цьому саме поняття текстури вважаємо феноменом людського сприйняття \cite{julesz1981}.
Гарна модель має мати достатньо велику кількість параметрів, щоб описати всі доречні типи текстур, 
і водночас достатньо малу, щоб допускати достатньо багато представників кожного типу.
Важливим критерієм якості моделі є можливість синтезу текстури за її параметрами, 
що демонструватиме одночасно обидва вищезгаданих аспекти \cite{simoncelli1998}. 
Додатково, спостереження як нашої лабораторії, так і інших дослідників, вказують на те, що текстура достатньо повно характеризується
статистиками у околі відносно малого радіуса, що дозволяє нехтувати взаємодією далеких пікселів.

Один зі способів опису текстури -- через коефіцієнти кореляції із певним набором фільтрів. 
Наприклад, коефіцієнти Фур'є, кореляцію з фільтрами Габора, коефіцієнтами розкладу 
кутового радіального перетворення (Angular radial transform) \cite{bober2001},
а також коефіцієнтами вейвлет-перетворення \cite{portilla2000}.
Великою папулярністю на сьогодні користуються моделі на основі штучних нейронних мереж, 
які у деякому сенсі підбирають доречний набір фільтрів для кожного набору тренувльних зображень автоматично, 
у вигляді вагів прихованих шарів \cite{Wang_2018_CVPR}.

Інший поширений підхід -- описувати текстуру через її статистичні властивості такі як вибіркова дисперсія в певному околі,
частоти n-грамів (co-occurence matrices, GLCM) та похідні від них склалярні статистики \cite{belsare2015}. 
Використовуються також моделі зображення як реалізації випадкового процесу: авторегресивні моделі з гаусовим шумом, 
Марківські випадкові поля, -- в цьому випадку параметри текстури визначаються як статистична оцінка параметрів цих випадкових процесів \cite{huawudeng2004, kashyap1986}. 

\section{Статистика LBP}\label{section1.lbp}

Нехай відображення \(I \colon K \to L$, $K \subset \Z^2$, $L \subset \Z\) 
буде одноканальним цифровим зображенням, 
де $K$ - множина двовимірних координат пікселів, $L$ - множина значень пікселів.
Надалі $K = \overline{0,W} \times \overline{0,H}$ та $L = \overline{0,255}$, 
де $W$ й $H$ - розміри зображення, а $\overline{a,b} = \{a, a+1, \dots , b\} \subset \Z$.

Довизначимо відображення $I$ на дробових координатах шляхом білінійної інтерполяції до $\hat I \colon [0,W] \times [0,H] \to [0,255]$, також розширивши множину значень.
\begin{equation}
\begin{split}\label{e:blinterp}
    \hat I(x+u,y+v) := \\
    (1 - u)(1 - v) & I(x,y) + (1-u) \cdot v \cdot I(x,y+1)\\ 
    + \; u \cdot (1-v) & I(x+1,y) + u \cdot v \cdot  I(x+1,y+1),
\end{split}
\end{equation}

де $x,y \in K$, $u,v \in [0,1)$. 
Наразі опускатимемо цю технічну деталь і використовуватимемо $I$ на позначення вже інтерпольованого зображення.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{img/bilinear-interpolation-1.png}
    \caption{
        Візуалізована білінійна інтерполяція в точці $(0.4,0.2)$ згідно формули \ref{e:blinterp}. 
        Значення в дробовій точці утворюється лінійною комбінацією значень у червоних точках на ґратці
        з коефіцієнтами, вказаними над точками.
    }
    \label{fig:bilinear-interp}
\end{figure}

Ідея статистики LBP \cite{ojala2002} полягає у використанні малої кількості тестових точок навколо пікселя для грубого опису поведінки його околу.
Побудуємо його з деяких простих міркувань.
Нехай все наше зображення містить лише одну текстуру.
У загальному випадку, статистика $T \colon K \to \R$ - це скалярна функція, визначена для кожного пікселя зображення. 
При цьому, нехай $N_c \subset K$ - множина координат пікселів, від значень яких залежить значення $T(c)$, $c \in K$. 
Вважатимемо, що $N_c$ будується для кожного пікселя однаково, на основі множини зсувів $R = \{r_i\} \subset \R^2$, $N_c = \{c' \mid c' - c \in R\}$, $0 \in R$.
Тоді $T(c) = T(g_0, g_1, g_2, \dots, g_n)$, де $g_i = I(c_i)$, $c_i \in N_c \setminus \{c\}$, $g_0 = I(c)$, $|N_c| = n+1$.

LBP побудований в першу чергу з міркувань інваріантності відносно контрастності зображення.
Також, емпірично відомо, що значення "центрального"{} пікселя несе мало інформації, а важливішими є відносні значення рівнів.  
Зміна контрастності зображення математично описується монотонним перетворенням значень його пікселів: $I' = G \circ I$, $G \colon [0,255] \to [0,255]$, де $G$ -- строго монотонна.
В такому разі, вимагаємо $T(g_0, g_1, ..., g_n) = T(G(g_0), G(g_1), ..., G(g_n))$.
Одне з допустимих визначень має вигляд $T = T(\{s(g_i - g_j) \mid 0\le i<j \le n\})$, де $s(x) = \1(x \ge 0)$.
Нехтуючи значенням центрального пікселя і відносними рівнями інших пікселів, можна спростити його до $T = T(\{s(g_i - g_0) \mid i=\overline{1,n}\})$.

Найповніший опис околу за таких умов був би самим бінарним вектором $\tilde T(c) \in \{0,1\}^n$,
де $\tilde T(c)_k = s(g_k - g_0)$, $k=\overline{1,n}$.
Бінарні вектори незручні у використанні у явному вигляді для комп'ютеризованих обчислень, проте, трактуючи їх як двійковий запис деякого числа, 
їх можна ототожнити із цілими числами. Математично така статистика формулюється як 
\begin{equation}\label{e:ojala-T}
    T(c) = T(s(g_1 - g_0), s(g_2 - g_0), ..., s(g_n - g_0)) = \sum_{k=1}^n 2^{k-1}s(g_k-g_0)
\end{equation}
На практиці, після $n=64$ числові значення $T$ виходять за межі діапазону значень типової цілочисленої змінної сучасних комп'ютерів довжиною в 64 біти, 
що робить околи більших розмірів недоцільними. У таких випадках доцільно розбивати більші околи на декілька менших, і працювати з вектором статистик відповідних околів,
що грубо відповідатиме конкатенації бітових векторів. 

Перейдемо до питання побудови околу $N_c$. 
Наразі статистика $T$ не є інваріантною відносно обертання, проте необхідною умовою для цього є розташування тестових точок $c_1,...,c_n$ у 
радіальній симетрії відносно центру $c$.
Через скінченну роздільну здатність зображення було би недоцільно розглядати симетрію відносно повороту на довільно малий кут.
Тому, прийнято дискретизувати простір кутів на $P$ значень і розглядати симетрію лише відносно поворотів на кути кратні $\frac{2\pi}{P}$.
Ціле число $P$ називатимемо \emph{рівнем дискретизації}, а $\frac{2\pi}{P}$ -- \emph{кутом дискретизації}. 

У загальному випадку, тестові точки $N_c$ можуть бути розташовані на колах різних радіусів. 
На практиці прийнято розділяти точки різних радіусів на різні околи, тому вважатимемо, що усі точки $c_1,...,c_n$ лежать на одному колі радіуса $R$.
Звідси, маємо, що всі точки мають бути рівномірно розподілені по колу з кроком, сумісним із $\frac{2\pi}{P}$.
Для визначенності, першу точку $c_1$ прийнято ставити праворуч від центру, за кутом 0 відносно горизонтальної осі, а наступні нумерувати за збільшенням кута.

Найчастіше, радіальний окіл $N_c$ радіуса $R$ та дискретизації $P$ має рівно $P$ точок і визначається як
\begin{equation}\label{e:circle}
    c_k = c_0 + R \cdot \begin{pmatrix} \cos \frac{2\pi (k-1)}{P} & \sin \frac{2\pi (k-1)}{P} \end{pmatrix}, \quad k=\overline{1,P}
\end{equation}
Зауважу, що точки околу переважно мають дробові координати, тобто значення $I(c_k)$ мають обчислюватися шляхом білінійної інтерполяції за формулою \ref{e:blinterp}.

\begin{figure}[h]
    \begin{subfigure}{0.48\textwidth}
    \includegraphics[width=0.9\linewidth]{img/clique-2.png} 
    \caption{
        Типовий окіл для обчислення інваріантної відносно обертання статистики із дискретизацією 8 або $\frac{\pi}{4}$. 
    }
    \label{fig:clique-2a}
    \end{subfigure}%
    \hfill
    \begin{subfigure}{0.48\textwidth}
    \includegraphics[width=0.9\linewidth]{img/clique-2-interp.png}
    \caption{
        Фактичні точки на ґратці, що приймають участь у обчисленні статистики на околі радіуса 2.
    }
    \label{fig:clique-2b}
    \end{subfigure}
    
    \caption{}
    \label{fig:clique-2}
\end{figure}


\subsection{Узагальнений \(LBP_{R,P}\)}\label{section1.1.a}\hfill

Узагальнені LBP коди \cite{ojala2002} визначаються в точності згідно формули \ref{e:ojala-T} на околі \ref{e:circle} з попередньої частини.
При цьому $R$ та $P$ є гіперпараметрами, підбір яких є нетривіальною задачею.
Поширено використання векторної статистики $T = \begin{pmatrix}
    LBP_{R_1,P_1} & ... & LBP_{R_m,P_m}
\end{pmatrix}$. В такому випадку, $P$ може однозначно залежати від $R$ \cite{fastlbp2024}, або залишатись сталим для всіх радіусів \cite{huawudeng2004}.
За параметрів $R=1$, $P=8$ ми отримуємо статистику, близьку до старішої статистики $LBP_8$, із єдиною різницею у тому, що окіл визначається не на колі, а на 8-ми сусідніх пікселях.


\subsection{Інваріантність відносно обертання у \(LBP_{R,P}^{ri}\)}\label{section1.1.c}\hfill

В основному, текстурні дескриптори розробляються у припущенні, що орієнтація текстур у тренувальних та тестових зображеннях співпадають.
Якщо орієнтація текстур довільна, то якість класифікації на основі цих дескрипторів стрімко падає. 
Очевидним рішенням буде доповнювати тренувальні дані синтетичними зображеннями, утвореними обертанням оригінальних. 
Іншим підходом буде використовувати в побудові дескриптора інваріантні статистики (напр. інваріантний LBP) чи 
"стерти"{} інформацію про орієнтацію зі статистик чи з дескриптора (напр. з допомогою DFT). 
На практиці, можна суттєво підняти точність класифікації, якщо розділити варіантні ознаки на інваріантні ознаки, та ознаки із інформацію про орієнтацію, наприклад з допомогою фільтрів Габора \cite{guo2010lbpv}. 

Нехай $\operatorname{rot} : \{0,1\}^P \to \{0,1\}^P$, 
$\operatorname{rot} \begin{pmatrix}a_1 & a_2 & ... & a_P\end{pmatrix} = \begin{pmatrix}a_P & a_1 & ... & a_{P-1}\end{pmatrix}$ 
-- оператор циклічної перестановки елементів вектора.
Введемо відношення еквівалентності $A\sim B \iff \exists k: A = \operatorname{rot}^k B$, де $A,B \in \{0,1\}^P$.
Зверну увагу, що $\operatorname{rot}^P A = A$ та $\operatorname{rot}^{P-k} \operatorname{rot}^k A = A$.

За цим відношенням еквівалентності розіб'ємо простір значень бінарного вектора $A = \begin{pmatrix}
    s(g_1 - g_0) & s(g_2 - g_0) & ... & s(g_P - g_0)
\end{pmatrix}$, з якого далі обчислюється статистика $LBP_{R,P}$. 
Циклічна перестановка цього вектора відповідає повороту окола $c_1, c_2, ..., c_P$ з \ref{e:circle} навколо $c_0$ на кут, кратний куту дискретизації.
Інваріантний відносно обертання дескриптор $LBP^{ri}$ обчислюється як найменше числове значення $LBP_{R,P}$ серед таких околів.
\begin{equation}
    LBP^{ri}_{R,P} = \min_{0\le k < P} LBP_{R,P} \left( \operatorname{rot}^k A \right) 
    = \min_{0\le k < P} \sum_{i=1}^P s(g_1 - g_0) 2^{i-1}.
\end{equation}
Фактично, для обчислення обирається циклічна перестановка $A$ із найбільшою кількістю нулів на початку.

Окрім набуття інваріантності, оператор $LBP^{ri}_{R,P}$ також зменшує розмір простору значень.
На множині представників класів еквівалентності $LBP^{ri}_{R,P}$ залишається ін'єктивним. 
Позначимо клас еквівалентності $A$ як $[A]$.
Розмір класів еквівалнетності не сталий і залежить від періоду вектора. 
Наприклад, $|[\texttt{00000000}]| = 1$, $|[\texttt{01010101}]| = |\{01010101,10101010\}| = 2$, $|[00100100]| = 8$.

Назвемо вектор періодичним з періодом $0<k\le P$, якщо $\operatorname{rot}^k A = A$ і $k$ є найменшим таким числом.
Вектор з періодом $P$ назвемо неперіодичним.
Зауважу, що не всі періоди можливі. Нехай $d=\operatorname{gcd}(k,P)$ -- найбільше спільне кратне, $d\le k < P$. 
Існують $r,s\in \Z$ такі, що $d=rk+sP$. Тоді $\operatorname{rot}^d A = \operatorname{rot}^{rk+sP} A = \operatorname{rot}^{rk} A = A$.
Але $k$ - найменше таке число, тобто $k \le d$, звідки маємо $d=k$. Таким чином, періоди -- це дільники $P$.
Зрозуміло, що клас еквівалентності $k$-періодичного вектора тоді має розмір $k$, проте кількість різних $k$-періодичних векторів нетривіальна.
Проте, зрозуміло, що $|\{A\in \{0,1\}^P \mid \operatorname{rot}^k A = A\}| = \operatorname{gcd}(k,P)$.  

Тоді, за лемою Бернсайда, $LBP^{ri}_{R,P}$ приймає $N^{ri}_P = \frac{1}{P}\sum_{k=1}^P 2^{\operatorname{gcd}(k,P)}$ різних значень. 
Ця величина природним чином є кількістю різних орбіт дії $\Z/P\Z$ на $\{0,1\}^P$, а також, кількістю різних двоколірних намист довжини $P$.
Асимптотично, $N^{ri}_P \sim \frac{2^P}{P} + o(2^P)$. 
Для прикладу, $N^{ri}_8 = 36$, $N^{ri}_{16} = 4116$, $N^{ri}_{24} = 699252$

У подальших дослідженнях було помічено, що для деяких застосувань та малих радіусів найчастіше (90\% та більше) трапляються так звані "рівномірні"{} послідовності, 
в яких є чітка межа між одиницями та нулями. Тобто, мінімальне представлення бінарного вектору $A$ матиме $u$ нулів, за якими йдуть $P-u$ одиниць.
Після цього спостереження розроблено "рівномірний"{}(uniform) $LBP^{riu}_{R,P}$, 
який ставить у відповідність рівномірному вектору кількість одиниць від $0$ до $P$, а нерівномірному -- спеціальне значення $P+1$.
$LBP^{riu}_{R,P}$ приймає $P+2$ різних значень.

У нашому дослідженні \cite{fastlbp2024} використовується саме цей варіант дескриптора LBP.
Його доцільність залишається дискусійним питанням, бо у випадку великих зображень та великих радіусів 
частка рівномірних околів стрімко зменшується.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.99\textwidth]{img/cloth-hist-lbpu.jpg}
    \caption{
        Гістограми LBP із різними R та P для двох текстур.
        Демонструється збільшення кількості нерівномірних околів зі збільшенням R.
    }
    \label{fig:cloth-hist-lbpu}
\end{figure}

\subsection{Частотне представлення кодів LBP}\label{section1.1.d}\hfill

Інший підхід полягає у застосуванні амплітуди дискретного перетворення Фур'є (DFT) LBP кодів у якості ознак \cite{arof1998, haley1999}.
Відомо, що DFT вектора не змінюється від його циклічних перестановок. 
Більше того, через симетричність амплітуди DFT відносно середини послідовності, достатньо зберігати лише половину координат, що зменшує кількість ознак. 

\subsection{Гістограма та класифікація текстур}\label{section1.1.f}\hfill

Маючи набір тренувальних зображень із відомими текстурами, можна класифікувати зображення невідомих текстур.
Припустимо, що всі зображення містять лише одну текстуру.
Розглянемо деяку статистику $T = T(c)$, визначену в кожному пікселі, що залежить від значень зображення у точках околу $N_c$ навколо цього пікселя.
Моделюватимемо текстуру як непараметричний розподіл статистики $T$ на зображенні.
Оцінкою розподілу буде гістограма значень $T$ серед усіх пікселів.

Побудова оцінки розподілу $T$ для якісної класифікації в подальшому, є зрозумілою задачею для дискретних $T$ (наприклад, $LBP^{riu}_{R,P}$ чи $LBP_{R,P}$) та менш очевидною для неперервних (наприклад, дійсних скалярних статистик).
В обох випадках потрібно забезпечити достатню кількість спостережень у кожному інтервалі гістограми.
На практиці використовуються $B$ інтервалів, які визначаються з тренувальних даних як персентилі рівня $\frac{1}{B}$, 
при чому кількість інтервалів $B$ визначається таким чином, щоб кожен інтервал мав достатньо спостережень (наприклад, 10). 
Для великих зображень із достатньою кількістю спостережень, кількість інтервалів обирають зважаючи на технічні обмеження обчислень.

Часто використовуються набори різних статистик $T_m$ (наприклад, LBP із різними параметрами R та P).
Особливо корисними вважаються сумісні розподіли дискретних статистик разом з неперервними \cite{guo2010lbpv}.
Математично строго було би використовувати сумісний розподіл цих статистик, який оцінюються багатовимірною гістограмою.
Розглядати сумісні розподіли багатьох статистик недоцільно, бо із зростанням кількості статистик експоненційно зростає кількість класів гістограми, 
збільшуючи довжину вектора ознак, та зменшуючи кількість спостережень кожного класу. 
У деяких випадках розглядають відособлені розподіли статистик замість сумісного, нехтуючи потенційними залежностями між ними.
Тоді класифікація відбуватиметься за декількома незалежними критеріями близкості розподілів. 
На практиці, це означає, що вектор ознак зображення утворюється конкатенацією гістограм декількох статистик.

Побудуємо процес класифікації на основі непараметричного критерію $\chi^2$ близкості імоврнісних розподілів статистики $T$ тренувальних та тестових зображень.
Почнемо з одного зображення. Позначимо гістограму відомого зображення як $M$, невідомого як $S$. 
Нульовою гіпотезою є те, що два зображення містять різні текстури, що відповідає різним розподілам текстурних дексрипторів $T$.
Альтернативною гіпотезою є те, що розподіли співпадають і два зображення містять одну і ту ж текстуру.

За нульової гіпотези, \todo{} \\
За альтернативної гіпотези, \todo{} \\
Статистику критерію побудуємо як відношення функцій правдоподібності \todo{}  \\
Спрощуємо статистику критерію до 
\begin{equation}\label{e:classify-1}
    G(S,M) = 2\sum_{b=1}^B S_b \log \frac{S_b}{M_b}
\end{equation}
$G$ також є відстанню Кульбака — Лейблера між емпіричними розподілами $S$ та $M$ (?). \\
\todo{КРитична область}

У випадку багатокласового класифікатора із відомими текстурами $M_i$, спостережуваному зображенню $S$ можна призначити клас текстури $M_i$ такий,
що максимізує величину
\begin{equation}\label{e:classify-2}
    L(S,M) = \sum_{b=1}^B S_b \log M_b.
\end{equation}

\todo{}

Отже, вектором ознак зображення може бути гістограма (як послідовність частот), конкатенація гістограм для різних параметрів, або значення комірок багатовимірної гістограми.
Поширеними класифікаторами є багатокласовий SVM із гаусовим ядром, та K-Nearest-Neighbors із \mbox{(псевдо-)метрикою} близкості розподілів.

%%

\section{Автокореляційні моделі з гаусовим шумом}\label{section1.2}

\subsection{Моделі малих порядків}\label{section1.2.a}
\hfill\\ \todo{Показати зв'язок із класичним LBP?}


\subsection{Інваріантність відносно обертання}\label{section1.2.b}
\hfill\\ \todo{Розказати про huawudeng2004: ICGMRF, ACGMRF}


\subsection{Збереження інформації про орієнтацію}\label{section1.2.с}
\hfill\\ \todo{Розказати про tip09\_liao\_law\_chung фільтри габора та PR\_10\_Mar\_LBPV principal' orientations.}


\section{Інші текстурні моделі}


%%

\section{Модель марківського випадкового поля на основі гістограм}\label{section1.3}

\todo{Опис МВП моделі зі статті Гімельфарба}

%%


\section{Вибір інформативних ознак}\label{section1.4}

\todo{Секція про метрику на гістограмах та порівняння різних групувань гістограм.}
\todo{Розказати роздуми та обґрунтування, чому KL може працювати краще ніж $\ell_1$ та $\ell_2$.}

%%

